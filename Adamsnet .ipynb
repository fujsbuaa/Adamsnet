{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import MNIST\n",
    "from datetime import datetime\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride = 1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
    "\n",
    "\n",
    "class adamsnet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(adamsnet, self).__init__()\n",
    "\n",
    "        self.k1 = torch.nn.Parameter(torch.Tensor(1).uniform_(0.0, 1.0))\n",
    "        self.k2 = torch.nn.Parameter(torch.Tensor(1).uniform_(0.0, 1.0))\n",
    "        self.k3 = torch.nn.Parameter(torch.Tensor(1).uniform_(0.0, 1.0))\n",
    "        self.k4 = torch.nn.Parameter(torch.Tensor(1).uniform_(0.0, 1.0))\n",
    "        self.k5 = torch.nn.Parameter(torch.Tensor(1).uniform_(0.0, 1.0))\n",
    "        self.k6 = torch.nn.Parameter(torch.Tensor(1).uniform_(0.0, 1.0))\n",
    "        self.k7 = torch.nn.Parameter(torch.Tensor(1).uniform_(0.0, 1.0))\n",
    "        self.k8 = torch.nn.Parameter(torch.Tensor(1).uniform_(0.0, 1.0))\n",
    "\n",
    "        self.MaxPool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv1x1_residual2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=1)\n",
    "        self.conv1x1_residual4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=1)\n",
    "        self.conv1x1_residual6 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=1)\n",
    "\n",
    "        self.conv0 = nn.Conv2d(in_channels, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.conv1 = conv3x3(in_channels=64, out_channels=64, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv2 = conv3x3(in_channels=64, out_channels=64, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv3 = conv3x3(in_channels=64, out_channels=64, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv4 = conv3x3(in_channels=64, out_channels=64, stride=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv5 = conv3x3(in_channels=64, out_channels=128, stride=2)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv6 = conv3x3(in_channels=128, out_channels=128, stride=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv7 = conv3x3(in_channels=128, out_channels=128, stride=1)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv8 = conv3x3(in_channels=128, out_channels=128, stride=1)\n",
    "        self.bn8 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.conv9 = conv3x3(in_channels=128, out_channels=256, stride=2)\n",
    "        self.bn9 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv10 = conv3x3(in_channels=256, out_channels=256, stride=1)\n",
    "        self.bn10 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv11 = conv3x3(in_channels=256, out_channels=256, stride=1)\n",
    "        self.bn11 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv12 = conv3x3(in_channels=256, out_channels=256, stride=1)\n",
    "        self.bn12 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv13 = conv3x3(in_channels=256, out_channels=512, stride=2)\n",
    "        self.bn13 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv14 = conv3x3(in_channels=512, out_channels=512, stride=1)\n",
    "        self.bn14 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv15 = conv3x3(in_channels=512, out_channels=512, stride=1)\n",
    "        self.bn15 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv16 = conv3x3(in_channels=512, out_channels=512, stride=1)\n",
    "        self.bn16 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.AvgPool = nn.AvgPool2d(4)\n",
    "\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = 1.0\n",
    "\n",
    "        out = self.conv0(x)\n",
    "        out_conv0 = out\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out)\n",
    "        out_conv2 = out\n",
    "        out += out_conv0\n",
    "        out = F.relu(out)\n",
    "        out_residual1 = out\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.bn4(out)\n",
    "        out = F.relu(out)\n",
    "        out_conv4 = self.MaxPool(out)\n",
    "        out_conv4 = self.conv1x1_residual2(out_conv4)\n",
    "        out = h * (1.0 - self.k2) * out + out_residual1 + h * self.k2 * out_conv2\n",
    "        out = F.relu(out)\n",
    "        out_residual2 = self.MaxPool(out)\n",
    "        out_residual2 = self.conv1x1_residual2(out_residual2)\n",
    "\n",
    "        out = self.conv5(out)\n",
    "        out = self.bn5(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv6(out)\n",
    "        out = self.bn6(out)\n",
    "        out = F.relu(out)\n",
    "        out_conv6 = out\n",
    "        out = h * (1.0 - self.k3) * out + out_residual2 + h * self.k3 * out_conv4\n",
    "        out = F.relu(out)\n",
    "        out_residual3 = out\n",
    "\n",
    "        out = self.conv7(out)\n",
    "        out = self.bn7(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv8(out)\n",
    "        out = self.bn8(out)\n",
    "        out = F.relu(out)\n",
    "        out_conv8 = self.MaxPool(out)\n",
    "        out_conv8 = self.conv1x1_residual4(out_conv8)\n",
    "        out = h * (1.0 - self.k4) * out + out_residual3 + h * self.k4 * out_conv6\n",
    "        out = F.relu(out)\n",
    "        out_residual4 = self.MaxPool(out)\n",
    "        out_residual4 = self.conv1x1_residual4(out_residual4)\n",
    "\n",
    "        out = self.conv9(out)\n",
    "        out = self.bn9(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv10(out)\n",
    "        out = self.bn10(out)\n",
    "        out = F.relu(out)\n",
    "        out_conv10 = out\n",
    "        out = h * (1.0 - self.k5) * out + out_residual4 + h * self.k5 * out_conv8\n",
    "        out = F.relu(out)\n",
    "        out_residual5 = out\n",
    "\n",
    "        out = self.conv11(out)\n",
    "        out = self.bn11(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv12(out)\n",
    "        out = self.bn12(out)\n",
    "        out = F.relu(out)\n",
    "        out_conv12 = self.MaxPool(out)\n",
    "        out_conv12 = self.conv1x1_residual6(out_conv12)\n",
    "        out = h * (1.0 - self.k6) * out + out_residual5 + h * self.k6 * out_conv10\n",
    "        out = F.relu(out)\n",
    "        out_residual6 = self.MaxPool(out)\n",
    "        out_residual6 = self.conv1x1_residual6(out_residual6)\n",
    "\n",
    "        out = self.conv13(out)\n",
    "        out = self.bn13(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv14(out)\n",
    "        out = self.bn14(out)\n",
    "        out = F.relu(out)\n",
    "        out_conv14 = out\n",
    "        out = h * (1.0 - self.k7) * out + out_residual6 + h * self.k7 * out_conv12\n",
    "        out = F.relu(out)\n",
    "        out_residual7 = out\n",
    "\n",
    "        out = self.conv15(out)\n",
    "        out = self.bn15(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv16(out)\n",
    "        out = self.bn16(out)\n",
    "        out = F.relu(out)\n",
    "        out_conv16 = out\n",
    "        out = h * (1.0 - self.k8) * out + out_residual7 + h * self.k8 * out_conv14\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out = self.AvgPool(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "#######################################\n",
    "# 测试\n",
    "test_net = adamsnet(3, 10)\n",
    "test_x = Variable(torch.zeros(1, 3, 32, 32))\n",
    "test_y = test_net(test_x)\n",
    "print('output: {}'.format(test_y.shape))\n",
    "#########################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_acc(output, label):\n",
    "    total = output.shape[0]\n",
    "    _, pred_label = output.max(1)\n",
    "    num_correct = (pred_label == label).sum().item()\n",
    "    return num_correct / total\n",
    "\n",
    "\n",
    "\n",
    "losses = []\n",
    "acces = []\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "\n",
    "def train(net, train_data, test_data, num_epochs, optimizer, criterion):\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.cuda()\n",
    "\n",
    "    prev_time = datetime.now()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        net = net.train()\n",
    "\n",
    "        for step, (im, label) in enumerate(train_data):\n",
    "            if torch.cuda.is_available():\n",
    "                im = Variable(im.cuda())  # (bs, 3, h, w)\n",
    "                label = Variable(label.cuda())  # (bs, h, w)\n",
    "            else:\n",
    "                im = Variable(im)\n",
    "                label = Variable(label)\n",
    "            # forward\n",
    "            output = net(im)\n",
    "            loss = criterion(output, label)\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_acc += get_acc(output, label)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            acces.append(train_acc / len(train_data))\n",
    "\n",
    "        cur_time = datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "\n",
    "        验证集\n",
    "        eval_loss = 0\n",
    "        eval_acc = 0\n",
    "        net = net.eval()\n",
    "        \n",
    "        for im, label in test_data:\n",
    "            if torch.cuda.is_available():\n",
    "                im = Variable(im.cuda())\n",
    "                label = Variable(label.cuda())\n",
    "            else:\n",
    "                im = Variable(im)\n",
    "                label = Variable(label)\n",
    "        \n",
    "            output = net(im)\n",
    "            loss = criterion(output, label)\n",
    "        \n",
    "            eval_loss += loss.item()\n",
    "            eval_acc += get_acc(output, label)\n",
    "        \n",
    "        eval_losses.append(eval_loss / len(test_data))\n",
    "        eval_acces.append(eval_acc / len(test_data))\n",
    "\n",
    "        epoch_str = (\n",
    "                \"Epoch %d. Train Loss: %f, Train Acc: %f, Eval Loss: %f, Eval Acc: %f, \"\n",
    "                % (epoch, train_loss / len(train_data),\n",
    "                   train_acc / len(train_data), eval_loss / len(test_data),\n",
    "                   eval_acc / len(test_data)))\n",
    "\n",
    "        epoch_str = (\n",
    "                \"Epoch %d. Train Loss: %f, Train Acc: %f\"\n",
    "                % (epoch, train_loss / len(train_data), train_acc / len(train_data)))\n",
    "\n",
    "        prev_time = cur_time\n",
    "        print(epoch_str + time_str)\n",
    "\n",
    "\n",
    "\n",
    "def data_tf(x):\n",
    "    x = x.resize((32, 32), 2)\n",
    "    x = np.array(x, dtype='float32') / 255\n",
    "    x = (x - 0.5) / 0.5\n",
    "    x = torch.from_numpy(x)\n",
    "    x = x.unsqueeze(0)\n",
    "    # 加噪\n",
    "    noise = torch.randn(x.size()) * 0.3\n",
    "    x = x + Variable(noise, requires_grad=False)\n",
    "    return x\n",
    "\n",
    "\n",
    "train_set = MNIST('./mnist', train=True, transform=data_tf, download=False)\n",
    "train_data = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_set = MNIST('./mnist', train=False, transform=data_tf, download=False)\n",
    "test_data = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "\n",
    "net = adamsnet(1, 10)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01, betas=(0.9, 0.99))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "# 画图\n",
    "im,la = train_set[0]\n",
    "print(im.shape,'label:',la)\n",
    "plt.imshow(im.squeeze(0))\n",
    "plt.show()\n",
    "\n",
    "# 训练\n",
    "train(net, train_data, test_data, 20, optimizer, criterion)\n",
    "\n",
    "\n",
    "# Loss曲线\n",
    "plt.plot(losses, color = 'red', label = 'train_loss')\n",
    "plt.xlabel('Iter')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.ylim(-0.2, 3)\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
